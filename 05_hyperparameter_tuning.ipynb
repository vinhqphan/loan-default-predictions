{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinh/miniconda3/envs/thesis/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "to_drop = ['loan_status', 'id', 'issue_d', 'year', 'grade', 'sub_grade']\n",
    "\n",
    "train_balanced = pd.read_csv('/Users/vinh/FS/thesis/data/train_balanced.csv')\n",
    "x_train_balanced = train_balanced.drop(to_drop, axis = 1)\n",
    "y_train_balanced = train_balanced[['loan_status']]\n",
    "\n",
    "val_final = pd.read_csv('/Users/vinh/FS/thesis/data/val_final.csv')\n",
    "x_val = val_final.drop(to_drop, axis = 1)\n",
    "y_val = val_final[['loan_status']]\n",
    "x_val_early_stop, x_val_scoring, y_val_early_stop, y_val_scoring = train_test_split(x_val, y_val, test_size = 0.50, random_state = 1337, stratify = y_val)\n",
    "\n",
    "test_final = pd.read_csv('/Users/vinh/FS/thesis/data/test_final.csv')\n",
    "x_test = test_final.drop(to_drop, axis = 1)\n",
    "y_test = test_final[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_results_df(target_true_values, model_prediction_dict):\n",
    "    '''\n",
    "    Creates dataframe that organizes result metrics across all models.\n",
    "\n",
    "    Arguments:\n",
    "        target_true_values: pd.DataFrame\n",
    "            True target values.\n",
    "\n",
    "        model_prediction_dict: dict\n",
    "            Dictionary containing predictions from all models.\n",
    "\n",
    "    Returns:\n",
    "        Dataframe containing results across all models.\n",
    "    '''\n",
    "    results_df = pd.DataFrame()\n",
    "    for k, v in model_prediction_dict.items():\n",
    "        temp_df = pd.DataFrame({k: [accuracy_score(target_true_values, v),\n",
    "                                    f1_score(target_true_values, v),\n",
    "                                    precision_score(target_true_values, v),\n",
    "                                    recall_score(target_true_values , v)]\n",
    "        })\n",
    "        results_df = pd.concat([results_df, temp_df], axis = 1)\n",
    "                                     \n",
    "    results_df = results_df.set_index(pd.Index(['Accuracy', 'F1-Score', 'Precision', 'Recall']))\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_predictions = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# XGBoost Balanced Train Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Optuna objective function ----\n",
    "def xgb_balanced_objective(trial):\n",
    "    clear_session()\n",
    "    \n",
    "    # Read in Data\n",
    "    to_drop = ['loan_status', 'id', 'issue_d', 'year', 'grade', 'sub_grade']\n",
    "\n",
    "    train_balanced = pd.read_csv('/Users/vinh/FS/thesis/data/train_balanced.csv')\n",
    "    x_train_balanced = train_balanced.drop(to_drop, axis = 1)\n",
    "    y_train_balanced = train_balanced[['loan_status']]\n",
    "\n",
    "    val_final = pd.read_csv('/Users/vinh/FS/thesis/data/val_final.csv')\n",
    "    x_val = val_final.drop(to_drop, axis = 1)\n",
    "    y_val = val_final[['loan_status']]\n",
    "    x_val_early_stop, x_val_scoring, y_val_early_stop, y_val_scoring = train_test_split(x_val, y_val, test_size = 0.50, random_state = 1337, stratify = y_val)\n",
    "    \n",
    "    # Optuna hyperparameter suggestions\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 9)\n",
    "    gamma = trial.suggest_float('gamma', 1e-8, 1.0, log = True)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 1e-8, 1.0, log = True) # L1 regularization weight.\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 1e-8, 1.0, log = True) # L2 regularization weight.\n",
    "    subsample = trial.suggest_float('subsample', 0.2, 1.0) # sampling ratio for training data.\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.2, 1.0) # sampling according to each tree.\n",
    "    \n",
    "    # Build model\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators = n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        gamma = gamma,\n",
    "        reg_alpha = reg_alpha, \n",
    "        reg_lambda = reg_lambda,\n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "        verbosity = 0,\n",
    "        objective = 'binary:logistic',\n",
    "        booster = 'gbtree',\n",
    "        random_state = 7,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    xgb_clf.fit(x_train_balanced, y_train_balanced,\n",
    "                early_stopping_rounds = 10,\n",
    "                eval_metric = 'auc',\n",
    "                eval_set = [(x_val_early_stop, y_val_early_stop)],\n",
    "                verbose = False\n",
    "    )\n",
    "    \n",
    "    # Evaluate F1 score on a validation set\n",
    "    pred = xgb_clf.predict(x_val_scoring)\n",
    "    score = f1_score(y_val_scoring, pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Optuna study ----\n",
    "xgb_balanced_study = optuna.create_study(study_name = 'xgb_balanced',\n",
    "                                         storage = 'sqlite:///data/optuna_trials/xgb_balanced.db',\n",
    "                                         load_if_exists = True,\n",
    "                                         direction = 'maximize'\n",
    ")\n",
    "xgb_balanced_study.optimize(xgb_balanced_objective, n_trials = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>params_reg_lambda</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.426464</td>\n",
       "      <td>2023-06-27 04:09:29.684552</td>\n",
       "      <td>2023-06-27 04:09:39.900140</td>\n",
       "      <td>0 days 00:00:10.215588</td>\n",
       "      <td>0.272047</td>\n",
       "      <td>2.090141e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>5.118262e-08</td>\n",
       "      <td>4.296916e-05</td>\n",
       "      <td>0.751606</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.428545</td>\n",
       "      <td>2023-06-27 04:09:39.906675</td>\n",
       "      <td>2023-06-27 04:09:50.387722</td>\n",
       "      <td>0 days 00:00:10.481047</td>\n",
       "      <td>0.643190</td>\n",
       "      <td>3.103960e-01</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>7.452729e-03</td>\n",
       "      <td>4.145269e-07</td>\n",
       "      <td>0.957249</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.428531</td>\n",
       "      <td>2023-06-27 04:09:50.394458</td>\n",
       "      <td>2023-06-27 04:10:00.113134</td>\n",
       "      <td>0 days 00:00:09.718676</td>\n",
       "      <td>0.882833</td>\n",
       "      <td>5.663288e-06</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>1.699173e-01</td>\n",
       "      <td>1.646163e-02</td>\n",
       "      <td>0.862509</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.426839</td>\n",
       "      <td>2023-06-27 04:10:00.120800</td>\n",
       "      <td>2023-06-27 04:10:12.365392</td>\n",
       "      <td>0 days 00:00:12.244592</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>6.292376e-05</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>9.188732e-02</td>\n",
       "      <td>1.323189e-08</td>\n",
       "      <td>0.821752</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.427723</td>\n",
       "      <td>2023-06-27 04:10:12.372362</td>\n",
       "      <td>2023-06-27 04:10:24.016908</td>\n",
       "      <td>0 days 00:00:11.644546</td>\n",
       "      <td>0.381242</td>\n",
       "      <td>5.812479e-03</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>2.710437e-06</td>\n",
       "      <td>5.715710e-01</td>\n",
       "      <td>0.855407</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0.429901</td>\n",
       "      <td>2023-06-27 07:51:55.775718</td>\n",
       "      <td>2023-06-27 07:52:09.219124</td>\n",
       "      <td>0 days 00:00:13.443406</td>\n",
       "      <td>0.570572</td>\n",
       "      <td>6.996957e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.672402e-07</td>\n",
       "      <td>7.834340e-06</td>\n",
       "      <td>0.788932</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.430551</td>\n",
       "      <td>2023-06-27 07:52:09.228999</td>\n",
       "      <td>2023-06-27 07:52:23.314543</td>\n",
       "      <td>0 days 00:00:14.085544</td>\n",
       "      <td>0.588980</td>\n",
       "      <td>7.232008e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>5.652292e-07</td>\n",
       "      <td>2.262151e-04</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0.431201</td>\n",
       "      <td>2023-06-27 07:52:23.327785</td>\n",
       "      <td>2023-06-27 07:52:36.996926</td>\n",
       "      <td>0 days 00:00:13.669141</td>\n",
       "      <td>0.646159</td>\n",
       "      <td>3.504050e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>2.705888e-01</td>\n",
       "      <td>2.584765e-01</td>\n",
       "      <td>0.973407</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>0.430046</td>\n",
       "      <td>2023-06-27 07:52:37.006731</td>\n",
       "      <td>2023-06-27 07:52:50.648925</td>\n",
       "      <td>0 days 00:00:13.642194</td>\n",
       "      <td>0.644777</td>\n",
       "      <td>5.672311e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>2.697373e-01</td>\n",
       "      <td>2.783055e-01</td>\n",
       "      <td>0.958214</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.429382</td>\n",
       "      <td>2023-06-27 07:52:50.657103</td>\n",
       "      <td>2023-06-27 07:53:05.088073</td>\n",
       "      <td>0 days 00:00:14.430970</td>\n",
       "      <td>0.632015</td>\n",
       "      <td>3.234424e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>9.035401e-02</td>\n",
       "      <td>1.677052e-01</td>\n",
       "      <td>0.935219</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "0         0  0.426464 2023-06-27 04:09:29.684552 2023-06-27 04:09:39.900140   \n",
       "1         1  0.428545 2023-06-27 04:09:39.906675 2023-06-27 04:09:50.387722   \n",
       "2         2  0.428531 2023-06-27 04:09:50.394458 2023-06-27 04:10:00.113134   \n",
       "3         3  0.426839 2023-06-27 04:10:00.120800 2023-06-27 04:10:12.365392   \n",
       "4         4  0.427723 2023-06-27 04:10:12.372362 2023-06-27 04:10:24.016908   \n",
       "..      ...       ...                        ...                        ...   \n",
       "995     995  0.429901 2023-06-27 07:51:55.775718 2023-06-27 07:52:09.219124   \n",
       "996     996  0.430551 2023-06-27 07:52:09.228999 2023-06-27 07:52:23.314543   \n",
       "997     997  0.431201 2023-06-27 07:52:23.327785 2023-06-27 07:52:36.996926   \n",
       "998     998  0.430046 2023-06-27 07:52:37.006731 2023-06-27 07:52:50.648925   \n",
       "999     999  0.429382 2023-06-27 07:52:50.657103 2023-06-27 07:53:05.088073   \n",
       "\n",
       "                  duration  params_colsample_bytree  params_gamma  \\\n",
       "0   0 days 00:00:10.215588                 0.272047  2.090141e-03   \n",
       "1   0 days 00:00:10.481047                 0.643190  3.103960e-01   \n",
       "2   0 days 00:00:09.718676                 0.882833  5.663288e-06   \n",
       "3   0 days 00:00:12.244592                 0.410891  6.292376e-05   \n",
       "4   0 days 00:00:11.644546                 0.381242  5.812479e-03   \n",
       "..                     ...                      ...           ...   \n",
       "995 0 days 00:00:13.443406                 0.570572  6.996957e-05   \n",
       "996 0 days 00:00:14.085544                 0.588980  7.232008e-02   \n",
       "997 0 days 00:00:13.669141                 0.646159  3.504050e-07   \n",
       "998 0 days 00:00:13.642194                 0.644777  5.672311e-07   \n",
       "999 0 days 00:00:14.430970                 0.632015  3.234424e-07   \n",
       "\n",
       "     params_max_depth  params_n_estimators  params_reg_alpha  \\\n",
       "0                   8                   87      5.118262e-08   \n",
       "1                   6                   50      7.452729e-03   \n",
       "2                   4                   54      1.699173e-01   \n",
       "3                   9                   51      9.188732e-02   \n",
       "4                   7                   93      2.710437e-06   \n",
       "..                ...                  ...               ...   \n",
       "995                 5                   84      1.672402e-07   \n",
       "996                 5                   95      5.652292e-07   \n",
       "997                 5                   87      2.705888e-01   \n",
       "998                 5                   88      2.697373e-01   \n",
       "999                 5                   89      9.035401e-02   \n",
       "\n",
       "     params_reg_lambda  params_subsample     state  \n",
       "0         4.296916e-05          0.751606  COMPLETE  \n",
       "1         4.145269e-07          0.957249  COMPLETE  \n",
       "2         1.646163e-02          0.862509  COMPLETE  \n",
       "3         1.323189e-08          0.821752  COMPLETE  \n",
       "4         5.715710e-01          0.855407  COMPLETE  \n",
       "..                 ...               ...       ...  \n",
       "995       7.834340e-06          0.788932  COMPLETE  \n",
       "996       2.262151e-04          0.999631  COMPLETE  \n",
       "997       2.584765e-01          0.973407  COMPLETE  \n",
       "998       2.783055e-01          0.958214  COMPLETE  \n",
       "999       1.677052e-01          0.935219  COMPLETE  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_xgb_balanced_study = optuna.load_study(study_name = 'xgb_balanced', storage = 'sqlite:///data/optuna_trials/xgb_balanced.db')\n",
    "load_xgb_balanced_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.672719740846669,\n",
       " 'gamma': 1.6323381093108538e-06,\n",
       " 'max_depth': 6,\n",
       " 'n_estimators': 91,\n",
       " 'reg_alpha': 0.16790562748458127,\n",
       " 'reg_lambda': 1.50865612415149e-06,\n",
       " 'subsample': 0.9988846052233982}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_xgb_balanced_study.best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- Testing optimal parameters model on test set ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.672719740846669, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1.6323381093108538e-06, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=91, n_jobs=-1,\n",
       "              num_parallel_tree=None, predictor=None, random_state=7, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.672719740846669, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1.6323381093108538e-06, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=91, n_jobs=-1,\n",
       "              num_parallel_tree=None, predictor=None, random_state=7, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.672719740846669, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=1.6323381093108538e-06, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=91, n_jobs=-1,\n",
       "              num_parallel_tree=None, predictor=None, random_state=7, ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators = load_xgb_balanced_study.best_params['n_estimators'],\n",
    "    max_depth = load_xgb_balanced_study.best_params['max_depth'],\n",
    "    gamma = load_xgb_balanced_study.best_params['gamma'],\n",
    "    reg_alpha = load_xgb_balanced_study.best_params['reg_alpha'], \n",
    "    reg_lambda = load_xgb_balanced_study.best_params['reg_lambda'],\n",
    "    subsample = load_xgb_balanced_study.best_params['subsample'],\n",
    "    colsample_bytree = load_xgb_balanced_study.best_params['colsample_bytree'],\n",
    "    verbosity = 0,\n",
    "    objective = 'binary:logistic',\n",
    "    booster = 'gbtree',\n",
    "    random_state = 7,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "xgb_clf.fit(x_train_balanced, y_train_balanced,\n",
    "            early_stopping_rounds = 10,\n",
    "            eval_metric = 'auc',\n",
    "            eval_set = [(x_val, y_val)],\n",
    "            verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_predictions['xgboost_balanced_tuned'] = xgb_clf.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# ANN Balanced Train Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Optuna objective function ----\n",
    "def ann_balanced_objective(trial):\n",
    "    clear_session()\n",
    "    \n",
    "    # Read in Data\n",
    "    to_drop = ['loan_status', 'id', 'issue_d', 'year', 'grade', 'sub_grade']\n",
    "\n",
    "    train_balanced = pd.read_csv('/Users/vinh/FS/thesis/data/train_balanced.csv')\n",
    "    x_train_balanced = train_balanced.drop(to_drop, axis = 1)\n",
    "    y_train_balanced = train_balanced[['loan_status']]\n",
    "\n",
    "    val_final = pd.read_csv('/Users/vinh/FS/thesis/data/val_final.csv')\n",
    "    x_val = val_final.drop(to_drop, axis = 1)\n",
    "    y_val = val_final[['loan_status']]\n",
    "    x_val_early_stop, x_val_scoring, y_val_early_stop, y_val_scoring = train_test_split(x_val, y_val, test_size = 0.50, random_state = 1337, stratify = y_val)\n",
    "    \n",
    "    # Optuna hyperparameter suggestions\n",
    "    hidden_layer_size = trial.suggest_int('hidden_layer_size', 10, 30)\n",
    "    hidden_layer_amount = trial.suggest_int('hidden_layer_amount', 2, 4)\n",
    "    hidden_layers = hidden_layer_amount * [hidden_layer_size]\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.4)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 48)\n",
    "    epochs = trial.suggest_int('epochs', 5, 20)\n",
    "    \n",
    "    # Build model\n",
    "    input_layer = Input(shape = (x_train_balanced.shape[1], ))\n",
    "    pointer_last_layer = input_layer\n",
    "\n",
    "    for layer in hidden_layers:\n",
    "        pointer_last_layer = Dense(layer, activation = 'relu')(pointer_last_layer)\n",
    "        pointer_last_layer = Dropout(dropout_rate)(pointer_last_layer)\n",
    "    \n",
    "    predictions = Dense(1, activation = 'sigmoid')(pointer_last_layer)\n",
    "\n",
    "    ann = Model(inputs = input_layer, outputs = predictions)\n",
    "    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "\n",
    "    ann_balanced = Model(inputs = input_layer, outputs = predictions)\n",
    "    ann_balanced.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "    \n",
    "    # Fit model\n",
    "    callback = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "    ann_balanced.fit(x = x_train_balanced, y = y_train_balanced,\n",
    "                     validation_data = (x_val_early_stop, y_val_early_stop),\n",
    "                     epochs = epochs,\n",
    "                     batch_size = batch_size,\n",
    "                     callbacks = [callback])\n",
    "    \n",
    "    # Evaluate F1 score on a validation set\n",
    "    pred = ann_balanced.predict(x_val_scoring)\n",
    "    pred = np.where(pred >= 0.5, 1, 0)\n",
    "    score = f1_score(y_val_scoring, pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Optuna study ----\n",
    "ann_balanced_study = optuna.create_study(study_name = 'ann_balanced',\n",
    "                                         storage = 'sqlite:///data/optuna_trials/ann_balanced.db',\n",
    "                                         load_if_exists = True,\n",
    "                                         direction = 'maximize'\n",
    ")\n",
    "ann_balanced_study.optimize(ann_balanced_objective, n_trials = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_dropout_rate</th>\n",
       "      <th>params_epochs</th>\n",
       "      <th>params_hidden_layer_amount</th>\n",
       "      <th>params_hidden_layer_size</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.411380</td>\n",
       "      <td>2023-06-27 11:40:41.612611</td>\n",
       "      <td>2023-06-27 11:52:39.623516</td>\n",
       "      <td>0 days 00:11:58.010905</td>\n",
       "      <td>48</td>\n",
       "      <td>0.258143</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.425964</td>\n",
       "      <td>2023-06-27 11:52:39.630649</td>\n",
       "      <td>2023-06-27 12:05:57.566694</td>\n",
       "      <td>0 days 00:13:17.936045</td>\n",
       "      <td>40</td>\n",
       "      <td>0.113585</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.088188</td>\n",
       "      <td>2023-06-27 12:05:57.573054</td>\n",
       "      <td>2023-06-27 12:22:03.551325</td>\n",
       "      <td>0 days 00:16:05.978271</td>\n",
       "      <td>31</td>\n",
       "      <td>0.346610</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.417593</td>\n",
       "      <td>2023-06-27 12:22:03.557224</td>\n",
       "      <td>2023-06-27 12:38:36.081288</td>\n",
       "      <td>0 days 00:16:32.524064</td>\n",
       "      <td>22</td>\n",
       "      <td>0.352721</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.423651</td>\n",
       "      <td>2023-06-27 12:38:36.087220</td>\n",
       "      <td>2023-06-27 12:55:57.056763</td>\n",
       "      <td>0 days 00:17:20.969543</td>\n",
       "      <td>18</td>\n",
       "      <td>0.125680</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.422386</td>\n",
       "      <td>2023-06-28 09:08:09.379520</td>\n",
       "      <td>2023-06-28 09:24:44.879551</td>\n",
       "      <td>0 days 00:16:35.500031</td>\n",
       "      <td>27</td>\n",
       "      <td>0.146679</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.426143</td>\n",
       "      <td>2023-06-28 09:24:44.886288</td>\n",
       "      <td>2023-06-28 09:35:37.605932</td>\n",
       "      <td>0 days 00:10:52.719644</td>\n",
       "      <td>36</td>\n",
       "      <td>0.124966</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.425068</td>\n",
       "      <td>2023-06-28 09:35:37.612597</td>\n",
       "      <td>2023-06-28 10:05:12.608579</td>\n",
       "      <td>0 days 00:29:34.995982</td>\n",
       "      <td>36</td>\n",
       "      <td>0.141802</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0.423984</td>\n",
       "      <td>2023-06-28 10:05:12.615005</td>\n",
       "      <td>2023-06-28 10:21:51.542977</td>\n",
       "      <td>0 days 00:16:38.927972</td>\n",
       "      <td>34</td>\n",
       "      <td>0.172678</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-28 10:21:51.549718</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>33</td>\n",
       "      <td>0.109773</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>RUNNING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.411380 2023-06-27 11:40:41.612611 2023-06-27 11:52:39.623516   \n",
       "1        1  0.425964 2023-06-27 11:52:39.630649 2023-06-27 12:05:57.566694   \n",
       "2        2  0.088188 2023-06-27 12:05:57.573054 2023-06-27 12:22:03.551325   \n",
       "3        3  0.417593 2023-06-27 12:22:03.557224 2023-06-27 12:38:36.081288   \n",
       "4        4  0.423651 2023-06-27 12:38:36.087220 2023-06-27 12:55:57.056763   \n",
       "..     ...       ...                        ...                        ...   \n",
       "66      66  0.422386 2023-06-28 09:08:09.379520 2023-06-28 09:24:44.879551   \n",
       "67      67  0.426143 2023-06-28 09:24:44.886288 2023-06-28 09:35:37.605932   \n",
       "68      68  0.425068 2023-06-28 09:35:37.612597 2023-06-28 10:05:12.608579   \n",
       "69      69  0.423984 2023-06-28 10:05:12.615005 2023-06-28 10:21:51.542977   \n",
       "70      70       NaN 2023-06-28 10:21:51.549718                        NaT   \n",
       "\n",
       "                 duration  params_batch_size  params_dropout_rate  \\\n",
       "0  0 days 00:11:58.010905                 48             0.258143   \n",
       "1  0 days 00:13:17.936045                 40             0.113585   \n",
       "2  0 days 00:16:05.978271                 31             0.346610   \n",
       "3  0 days 00:16:32.524064                 22             0.352721   \n",
       "4  0 days 00:17:20.969543                 18             0.125680   \n",
       "..                    ...                ...                  ...   \n",
       "66 0 days 00:16:35.500031                 27             0.146679   \n",
       "67 0 days 00:10:52.719644                 36             0.124966   \n",
       "68 0 days 00:29:34.995982                 36             0.141802   \n",
       "69 0 days 00:16:38.927972                 34             0.172678   \n",
       "70                    NaT                 33             0.109773   \n",
       "\n",
       "    params_epochs  params_hidden_layer_amount  params_hidden_layer_size  \\\n",
       "0              18                           4                        25   \n",
       "1              15                           4                        19   \n",
       "2              15                           4                        20   \n",
       "3               7                           2                        30   \n",
       "4              12                           2                        17   \n",
       "..            ...                         ...                       ...   \n",
       "66             12                           2                        25   \n",
       "67             19                           2                        22   \n",
       "68             19                           2                        23   \n",
       "69             18                           2                        25   \n",
       "70             17                           2                        22   \n",
       "\n",
       "       state  \n",
       "0   COMPLETE  \n",
       "1   COMPLETE  \n",
       "2   COMPLETE  \n",
       "3   COMPLETE  \n",
       "4   COMPLETE  \n",
       "..       ...  \n",
       "66  COMPLETE  \n",
       "67  COMPLETE  \n",
       "68  COMPLETE  \n",
       "69  COMPLETE  \n",
       "70   RUNNING  \n",
       "\n",
       "[71 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ann_balanced_study = optuna.load_study(study_name = 'ann_balanced', storage = 'sqlite:///data/optuna_trials/ann_balanced.db')\n",
    "load_ann_balanced_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 42,\n",
       " 'dropout_rate': 0.13143473371119396,\n",
       " 'epochs': 19,\n",
       " 'hidden_layer_amount': 2,\n",
       " 'hidden_layer_size': 24}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_ann_balanced_study.best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---- Testing optimal parameters model on test set ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 10:35:42.941308: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9297/9297 [==============================] - 87s 9ms/step - loss: 0.6329 - val_loss: 0.6250\n",
      "Epoch 2/19\n",
      "9297/9297 [==============================] - 84s 9ms/step - loss: 0.6274 - val_loss: 0.6285\n",
      "Epoch 3/19\n",
      "9297/9297 [==============================] - 82s 9ms/step - loss: 0.6262 - val_loss: 0.6416\n",
      "Epoch 4/19\n",
      "9297/9297 [==============================] - 80s 9ms/step - loss: 0.6254 - val_loss: 0.6199\n",
      "Epoch 5/19\n",
      "9297/9297 [==============================] - 81s 9ms/step - loss: 0.6249 - val_loss: 0.6347\n",
      "Epoch 6/19\n",
      "9297/9297 [==============================] - 82s 9ms/step - loss: 0.6245 - val_loss: 0.6220\n",
      "Epoch 7/19\n",
      "9297/9297 [==============================] - 82s 9ms/step - loss: 0.6241 - val_loss: 0.5990\n",
      "Epoch 8/19\n",
      "9297/9297 [==============================] - 83s 9ms/step - loss: 0.6238 - val_loss: 0.6164\n",
      "Epoch 9/19\n",
      "9297/9297 [==============================] - 85s 9ms/step - loss: 0.6234 - val_loss: 0.6399\n",
      "Epoch 10/19\n",
      "9297/9297 [==============================] - 85s 9ms/step - loss: 0.6232 - val_loss: 0.6368\n",
      "Epoch 11/19\n",
      "9297/9297 [==============================] - 79s 9ms/step - loss: 0.6231 - val_loss: 0.6087\n",
      "Epoch 12/19\n",
      "9297/9297 [==============================] - 79s 8ms/step - loss: 0.6228 - val_loss: 0.6088\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "hidden_layer_size = load_ann_balanced_study.best_params['hidden_layer_size']\n",
    "hidden_layer_amount = load_ann_balanced_study.best_params['hidden_layer_amount']\n",
    "hidden_layers = hidden_layer_amount * [hidden_layer_size]\n",
    "dropout_rate = load_ann_balanced_study.best_params['dropout_rate']\n",
    "batch_size = load_ann_balanced_study.best_params['batch_size']\n",
    "epochs = load_ann_balanced_study.best_params['epochs']\n",
    "    \n",
    "input_layer = Input(shape = (x_train_balanced.shape[1], ))\n",
    "pointer_last_layer = input_layer\n",
    "\n",
    "for layer in hidden_layers:\n",
    "    pointer_last_layer = Dense(layer, activation = 'relu')(pointer_last_layer)\n",
    "    pointer_last_layer = Dropout(dropout_rate)(pointer_last_layer)\n",
    "\n",
    "predictions = Dense(1, activation = 'sigmoid')(pointer_last_layer)\n",
    "\n",
    "ann = Model(inputs = input_layer, outputs = predictions)\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "\n",
    "ann_balanced = Model(inputs = input_layer, outputs = predictions)\n",
    "ann_balanced.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "\n",
    "    \n",
    "# Fit model\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "ann_balanced_history = ann_balanced.fit(x = x_train_balanced, y = y_train_balanced,\n",
    "                                        validation_data = (x_val, y_val),\n",
    "                                        epochs = epochs,\n",
    "                                        batch_size = batch_size,\n",
    "                                        callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8266/8266 [==============================] - 13s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ann_balanced_tuned_pred = ann_balanced_history.model.predict(x_test)\n",
    "ann_balanced_tuned_pred = np.where(ann_balanced_tuned_pred >= 0.5, 1, 0)\n",
    "tuned_model_predictions['ann_balanced_tuned'] = ann_balanced_tuned_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Tuned Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost_balanced_tuned</th>\n",
       "      <td>0.645038</td>\n",
       "      <td>0.428010</td>\n",
       "      <td>0.314057</td>\n",
       "      <td>0.671747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ann_balanced_tuned</th>\n",
       "      <td>0.660241</td>\n",
       "      <td>0.424305</td>\n",
       "      <td>0.319022</td>\n",
       "      <td>0.633309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1-Score  Precision    Recall\n",
       "xgboost_balanced_tuned  0.645038  0.428010   0.314057  0.671747\n",
       "ann_balanced_tuned      0.660241  0.424305   0.319022  0.633309"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_final_results_df(y_test, tuned_model_predictions).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
